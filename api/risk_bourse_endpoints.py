"""
Risk Management Endpoints pour Bourse/Saxo

Fournit les métriques de risque pour portfolios actions/ETF/obligations.
Utilise le nouveau BourseRiskCalculator avec support yfinance.

IMPORTANT: Multi-tenant strict - tous les endpoints acceptent user_id obligatoire.
"""

from __future__ import annotations
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime
from fastapi import APIRouter, Query, HTTPException, Depends
from pydantic import BaseModel, Field

from services.risk.bourse.calculator import BourseRiskCalculator
from services.risk.bourse.alerts import BourseAlertsDetector
from services.risk.bourse.alerts_persistence import AlertsPersistenceService
from api.deps import get_required_user
from api.deps import get_redis_client

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/risk/bourse", tags=["risk-management-bourse"])


class RiskDashboardResponse(BaseModel):
    """Response model for bourse risk dashboard"""
    ok: bool
    coverage: float = Field(description="Coverage ratio (0.0-1.0)")
    positions_count: int
    total_value_usd: float
    risk: Dict[str, Any]
    asof: str
    user_id: str


@router.get("/dashboard", response_model=RiskDashboardResponse)
async def bourse_risk_dashboard(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None, description="Specific Saxo file to use (CSV mode)"),
    source: Optional[str] = Query(None, description="Data source (API mode): saxobank_api"),
    min_usd: float = Query(1.0, ge=0.0, description="Minimum position value in USD"),
    lookback_days: int = Query(252, ge=30, le=730, description="Days of price history for metrics"),
    risk_free_rate: float = Query(0.03, ge=0.0, le=0.20, description="Annual risk-free rate"),
    var_method: str = Query("historical", description="VaR calculation method"),
    cash_amount: Optional[float] = Query(None, ge=0.0, description="Cash/liquidities in USD")
) -> RiskDashboardResponse:
    """
    Calculer les métriques de risque pour un portfolio Bourse/Saxo.

    Utilise le nouveau BourseRiskCalculator avec support yfinance pour données historiques.

    Args:
        user_id: ID utilisateur (isolation multi-tenant)
        file_key: Clé du fichier Saxo spécifique (CSV mode)
        source: Data source pour API mode (saxobank_api)
        min_usd: Valeur minimum position USD à inclure
        lookback_days: Jours d'historique prix pour calculs
        risk_free_rate: Taux sans risque annuel pour Sharpe/Sortino
        var_method: Méthode VaR (historical|parametric|montecarlo)
        cash_amount: Montant des liquidités disponibles en USD (optionnel)

    Returns:
        RiskDashboardResponse avec score + métriques complètes

    Examples:
        CSV: GET /api/risk/bourse/dashboard?user_id=jack&file_key=portfolio.csv
        API: GET /api/risk/bourse/dashboard?user_id=jack&source=saxobank_api
    """
    try:
        logger.info(f"[risk-bourse] Computing risk dashboard for user {user_id} (source={source}, file_key={file_key})")

        # 1) Récupérer positions depuis Manual/API/CSV
        if source == "manual_bourse":
            # Manual mode: charger depuis Sources V2
            from services.sources import source_registry
            from pathlib import Path

            project_root = Path(__file__).parent.parent
            manual_source = source_registry.get_source("manual_bourse", user_id, project_root)

            if not manual_source:
                logger.warning(f"[risk-bourse] Manual bourse source not found for user {user_id}")
                return RiskDashboardResponse(
                    ok=True,
                    coverage=0.0,
                    positions_count=0,
                    total_value_usd=0.0,
                    risk={
                        "score": 0,
                        "level": "N/A",
                        "metrics": {},
                        "message": "Manual bourse source not available"
                    },
                    asof=datetime.utcnow().isoformat(),
                    user_id=user_id
                )

            result = await manual_source.get_balances()
            # get_balances() returns List[BalanceItem] directly, not a dict
            items = result if isinstance(result, list) else []

            if not items:
                logger.warning(f"[risk-bourse] No manual positions for user {user_id}")
                return RiskDashboardResponse(
                    ok=True,
                    coverage=0.0,
                    positions_count=0,
                    total_value_usd=0.0,
                    risk={
                        "score": 0,
                        "level": "N/A",
                        "metrics": {},
                        "message": "No manual positions available"
                    },
                    asof=datetime.utcnow().isoformat(),
                    user_id=user_id
                )

            # Transform BalanceItem (dataclass) to positions format
            positions = [
                {
                    "symbol": item.symbol,
                    "asset_name": item.alias or item.symbol,
                    "quantity": float(item.amount or 0),
                    "market_value_usd": float(item.value_usd or 0),
                    "asset_class": item.asset_class or "EQUITY",
                    "currency": item.currency or "USD",
                    "broker": item.location or "Manual",
                    "avg_price": item.avg_price or 0
                }
                for item in items
            ]

        elif source == "saxobank_api":
            # API mode: charger depuis l'endpoint API
            from services.saxo_auth_service import SaxoAuthService
            auth_service = SaxoAuthService(user_id)

            # Charger positions cachées si disponibles
            positions = await auth_service.get_cached_positions(max_age_hours=1)

            if not positions:
                logger.warning(f"[risk-bourse] No cached API positions for user {user_id}")
                return RiskDashboardResponse(
                    ok=True,
                    coverage=0.0,
                    positions_count=0,
                    total_value_usd=0.0,
                    risk={
                        "score": 0,
                        "level": "N/A",
                        "metrics": {},
                        "message": "No API positions available (try refreshing saxo-dashboard first)"
                    },
                    asof=datetime.utcnow().isoformat(),
                    user_id=user_id
                )

        else:
            # CSV mode: utiliser l'adaptateur
            from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail

            portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)

            if not portfolios:
                return RiskDashboardResponse(
                    ok=True,
                    coverage=0.0,
                    positions_count=0,
                    total_value_usd=0.0,
                    risk={
                        "score": 0,
                        "level": "N/A",
                        "metrics": {},
                        "message": "No Saxo portfolios found for this user"
                    },
                    asof=datetime.utcnow().isoformat(),
                    user_id=user_id
                )

            portfolio_id = portfolios[0].get("portfolio_id")
            portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
            positions = portfolio_data.get("positions", [])

        if not positions:
            return RiskDashboardResponse(
                ok=True,
                coverage=0.0,
                positions_count=0,
                total_value_usd=0.0,
                risk={
                    "score": 0,
                    "level": "N/A",
                    "metrics": {},
                    "message": "No positions found in portfolio"
                },
                asof=datetime.utcnow().isoformat(),
                user_id=user_id
            )

        # Filtrer par seuil minimum
        positions_filtered = [p for p in positions if p.get("market_value_usd", 0.0) >= min_usd]

        if not positions_filtered:
            total_value = sum(p.get("market_value_usd", 0.0) for p in positions)
            return RiskDashboardResponse(
                ok=True,
                coverage=0.0,
                positions_count=len(positions),
                total_value_usd=total_value,
                risk={
                    "score": 0,
                    "level": "N/A",
                    "metrics": {},
                    "message": f"All positions below ${min_usd} threshold"
                },
                asof=datetime.utcnow().isoformat(),
                user_id=user_id
            )

        # 2) Calculer risque avec BourseRiskCalculator
        calculator = BourseRiskCalculator(data_source="yahoo")

        risk_result = await calculator.calculate_portfolio_risk(
            positions=positions_filtered,
            benchmark="SPY",  # S&P500 par défaut
            lookback_days=lookback_days,
            risk_free_rate=risk_free_rate,
            var_method=var_method
        )

        # 3) Formater réponse
        total_value = risk_result["metadata"]["portfolio_value"]

        # Add cash/liquidities to total value if provided
        total_value_with_cash = total_value
        if cash_amount and cash_amount > 0:
            total_value_with_cash = total_value + cash_amount
            logger.info(f"[risk-bourse] Including cash: ${cash_amount:,.2f}, Total: ${total_value_with_cash:,.2f}")

        risk_score = risk_result["risk_score"]["risk_score"]
        risk_level = risk_result["risk_score"]["risk_level"]

        # Métriques détaillées
        metrics = risk_result["traditional_risk"]

        # Add cash info to metrics if provided
        if cash_amount and cash_amount > 0:
            metrics["cash_amount"] = cash_amount
            metrics["cash_percentage"] = (cash_amount / total_value_with_cash * 100) if total_value_with_cash > 0 else 0

        # Coverage (proxy basé sur disponibilité données)
        coverage = min(1.0, len(positions_filtered) / max(1, len(positions)))

        return RiskDashboardResponse(
            ok=True,
            coverage=coverage,
            positions_count=len(positions_filtered),
            total_value_usd=total_value_with_cash,
            risk={
                "score": risk_score,
                "level": risk_level,
                "metrics": metrics
            },
            asof=datetime.utcnow().isoformat(),
            user_id=user_id
        )

    except Exception as e:
        logger.exception(f"[risk-bourse] Error computing risk dashboard for user {user_id}: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Risk dashboard computation failed: {str(e)}"
        )


# Helper functions removed - now handled by BourseRiskCalculator


# ==================== ADVANCED ANALYTICS ENDPOINTS ====================

@router.get("/advanced/position-var")
async def get_position_var(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None, description="Specific Saxo file to use"),
    confidence_level: float = Query(0.95, ge=0.8, le=0.99),
    lookback_days: int = Query(252, ge=30, le=730)
) -> dict:
    """
    Calculate position-level VaR (marginal & component VaR)

    Returns VaR contribution for each position in the portfolio.

    Example:
        GET /api/risk/bourse/advanced/position-var?user_id=jack&confidence_level=0.95
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.advanced_analytics import AdvancedRiskAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[position-var] Computing for user {user_id}")

        # Get portfolio data
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        if len(positions) < 2:
            raise HTTPException(status_code=400, detail="Need at least 2 positions for VaR decomposition")

        # Fetch historical returns for all positions
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=lookback_days + 30)

        positions_returns = {}
        portfolio_weights = {}
        total_value = sum(pos.get('market_value_usd', 0) for pos in positions)

        for pos in positions:
            ticker = pos.get('ticker') or pos.get('symbol')
            if not ticker:
                continue

            try:
                price_data = await data_fetcher.fetch_historical_prices(
                    ticker=ticker,
                    start_date=start_date,
                    end_date=end_date
                )

                if len(price_data) < 30:
                    continue

                # Calculate returns
                returns = price_data['close'].pct_change().dropna()
                positions_returns[ticker] = returns

                # Weight in portfolio
                weight = pos.get('market_value_usd', 0) / total_value if total_value > 0 else 0
                portfolio_weights[ticker] = weight

            except Exception as e:
                logger.warning(f"Failed to fetch data for {ticker}: {e}")
                continue

        if len(positions_returns) < 2:
            raise HTTPException(status_code=400, detail="Insufficient data for position VaR")

        # Calculate position-level VaR
        analytics = AdvancedRiskAnalytics()
        result = analytics.calculate_position_var(
            positions_returns=positions_returns,
            portfolio_weights=portfolio_weights,
            confidence_level=confidence_level
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[position-var] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/advanced/correlation")
async def get_correlation_matrix(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    method: str = Query("pearson", description="Correlation method"),
    lookback_days: int = Query(252, ge=30, le=730)
) -> dict:
    """
    Calculate correlation matrix between positions

    Returns correlation matrix with hierarchical clustering.

    Example:
        GET /api/risk/bourse/advanced/correlation?user_id=jack&method=pearson
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.advanced_analytics import AdvancedRiskAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[correlation] Computing for user {user_id}")

        # Get positions (similar to position-var)
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        # Fetch returns
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=lookback_days + 30)

        positions_returns = {}
        for pos in positions:
            ticker = pos.get('ticker') or pos.get('symbol')
            if not ticker:
                continue

            try:
                price_data = await data_fetcher.fetch_historical_prices(ticker, start_date, end_date)
                if len(price_data) >= 30:
                    returns = price_data['close'].pct_change().dropna()
                    positions_returns[ticker] = returns
            except Exception as e:
                logger.warning(f"Failed to fetch {ticker}: {e}")

        if len(positions_returns) < 2:
            raise HTTPException(status_code=400, detail="Need at least 2 positions")

        # Calculate correlation
        analytics = AdvancedRiskAnalytics()
        result = analytics.calculate_correlation_matrix(
            positions_returns=positions_returns,
            method=method
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[correlation] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/advanced/stress-test")
async def run_stress_test(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    scenario: str = Query("market_crash", description="Stress scenario name"),
    market_shock: Optional[float] = Query(None, description="Market shock percentage for custom scenario"),
    custom_shocks: Optional[Dict[str, float]] = None
) -> dict:
    """
    Run stress test on portfolio

    Scenarios: market_crash, market_rally, moderate_selloff, rate_hike, flash_crash, covid_crash, custom

    Example:
        POST /api/risk/bourse/advanced/stress-test?scenario=market_crash
        POST /api/risk/bourse/advanced/stress-test?scenario=custom&market_shock=-0.15
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.advanced_analytics import AdvancedRiskAnalytics

        logger.info(f"[stress-test] Running scenario '{scenario}' for user {user_id}")

        # Get positions
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        # Prepare positions data
        # Use market_value directly since Saxo positions don't separate price/quantity
        positions_data = {}
        for pos in positions:
            ticker = pos.get('ticker') or pos.get('symbol')
            if not ticker:
                continue

            market_value = pos.get('market_value_usd', 0)
            # Simulate price=1, quantity=market_value for stress test
            positions_data[ticker] = {
                'current_price': 1.0,
                'quantity': market_value
            }

        # Convert market_shock to custom_shocks if provided
        if scenario == 'custom' and market_shock is not None and custom_shocks is None:
            custom_shocks = {ticker: market_shock for ticker in positions_data.keys()}
            logger.info(f"[stress-test] Using market_shock={market_shock} for all positions")

        # Run stress test
        analytics = AdvancedRiskAnalytics()
        result = analytics.run_stress_test(
            positions_data=positions_data,
            scenario=scenario,
            custom_shocks=custom_shocks
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[stress-test] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/advanced/fx-exposure")
async def get_fx_exposure(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    base_currency: str = Query("USD", description="Base currency for reporting")
) -> dict:
    """
    Analyze currency exposure in portfolio

    Returns FX exposure breakdown with hedging suggestions.

    Example:
        GET /api/risk/bourse/advanced/fx-exposure?user_id=jack&base_currency=USD
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.advanced_analytics import AdvancedRiskAnalytics

        logger.info(f"[fx-exposure] Analyzing for user {user_id}")

        # Get positions
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        # Analyze FX exposure
        analytics = AdvancedRiskAnalytics()
        result = analytics.analyze_fx_exposure(
            positions=positions,
            base_currency=base_currency
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[fx-exposure] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ==================== SPECIALIZED ANALYTICS ENDPOINTS ====================

@router.get("/specialized/earnings")
async def get_earnings_prediction(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    ticker: str = Query(..., description="Ticker to analyze"),
    lookback_days: int = Query(365, ge=30, le=1825)
) -> dict:
    """
    Predict earnings impact on volatility

    Returns earnings predictions with alerts for upcoming earnings dates.

    Example:
        GET /api/risk/bourse/specialized/earnings?user_id=jack&ticker=AAPL
    """
    try:
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[earnings] Analyzing {ticker} for user {user_id}")

        # Fetch historical price data
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=lookback_days + 30)

        price_data = await data_fetcher.fetch_historical_prices(
            ticker=ticker,
            start_date=start_date,
            end_date=end_date
        )

        if len(price_data) < 60:
            raise HTTPException(status_code=400, detail=f"Insufficient data for {ticker}")

        # Analyze earnings impact
        # Note: earnings_dates would come from an API (e.g., yfinance, Financial Modeling Prep)
        # For now, we'll use None and the analyzer will provide generic estimates
        analytics = SpecializedBourseAnalytics()
        result = analytics.predict_earnings_impact(
            ticker=ticker,
            price_history=price_data,
            earnings_dates=None  # TODO: Integrate earnings calendar API
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[earnings] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/specialized/sector-rotation")
async def get_sector_rotation(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    lookback_days: int = Query(60, ge=30, le=180)
) -> dict:
    """
    Detect sector rotation patterns

    Returns sector performance metrics with rotation signals.

    Example:
        GET /api/risk/bourse/specialized/sector-rotation?user_id=jack&lookback_days=60
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[sector-rotation] Analyzing for user {user_id}")

        # Get portfolio positions
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        # Fetch returns for all positions
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=lookback_days + 30)

        positions_returns = {}
        positions_values = {}  # For weight calculation

        for pos in positions:
            ticker = pos.get('ticker') or pos.get('symbol') or pos.get('Symbol')
            if not ticker:
                continue

            # Store position value for weight calculation
            # Try multiple possible keys for position value
            value_eur = (
                pos.get('value_eur') or
                pos.get('value_usd') or
                pos.get('market_value') or
                pos.get('Market Value') or
                pos.get('current_value_eur') or
                pos.get('current_value_usd') or
                0.0
            )

            # Debug: Log first position to identify correct key
            if not positions_values and value_eur == 0.0:
                logger.warning(f"[sector-rotation] Position {ticker} has 0 value. Available keys: {list(pos.keys())[:10]}")

            if value_eur > 0:
                positions_values[ticker] = float(value_eur)

            try:
                price_data = await data_fetcher.fetch_historical_prices(ticker, start_date, end_date)
                if len(price_data) >= 30:
                    returns = price_data['close'].pct_change().dropna()
                    positions_returns[ticker] = returns
            except Exception as e:
                logger.warning(f"Failed to fetch {ticker}: {e}")

        if len(positions_returns) < 2:
            raise HTTPException(status_code=400, detail="Need at least 2 positions")

        # Detect sector rotation
        analytics = SpecializedBourseAnalytics()
        result = analytics.detect_sector_rotation(
            positions_returns=positions_returns,
            lookback_days=lookback_days,
            positions_values=positions_values
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[sector-rotation] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/specialized/beta-forecast")
async def get_beta_forecast(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    ticker: str = Query(..., description="Ticker to analyze"),
    benchmark: str = Query("SPY", description="Benchmark ticker"),
    forecast_method: str = Query("ewma", description="Forecast method"),
    lookback_days: int = Query(252, ge=60, le=730)
) -> dict:
    """
    Forecast dynamic beta vs benchmark

    Returns beta forecast with trend analysis.

    Example:
        GET /api/risk/bourse/specialized/beta-forecast?user_id=jack&ticker=AAPL&benchmark=SPY
    """
    try:
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[beta-forecast] Analyzing {ticker} vs {benchmark} for user {user_id}")

        # Fetch historical data
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=lookback_days + 30)

        # Get position and benchmark data
        position_data = await data_fetcher.fetch_historical_prices(ticker, start_date, end_date)
        benchmark_data = await data_fetcher.fetch_benchmark_prices(benchmark, start_date, end_date)

        if len(position_data) < 60 or len(benchmark_data) < 60:
            raise HTTPException(status_code=400, detail="Insufficient data")

        # Calculate returns
        position_returns = position_data['close'].pct_change().dropna()
        benchmark_returns = benchmark_data['close'].pct_change().dropna()

        # Forecast beta
        analytics = SpecializedBourseAnalytics()
        result = analytics.forecast_beta(
            position_returns=position_returns,
            benchmark_returns=benchmark_returns,
            forecast_method=forecast_method
        )

        return {
            "ok": True,
            "user_id": user_id,
            "ticker": ticker,
            "benchmark": benchmark,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[beta-forecast] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/specialized/dividends")
async def get_dividend_analysis(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    ticker: str = Query(..., description="Ticker to analyze")
) -> dict:
    """
    Analyze dividend impact and yield

    Returns dividend analysis with yield and ex-dividend dates.

    Example:
        GET /api/risk/bourse/specialized/dividends?user_id=jack&ticker=AAPL
    """
    try:
        from services.risk.bourse.data_fetcher import BourseDataFetcher
        from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics
        from datetime import datetime, timedelta

        logger.info(f"[dividends] Analyzing {ticker} for user {user_id}")

        # Fetch historical price data
        data_fetcher = BourseDataFetcher()
        end_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        start_date = end_date - timedelta(days=730)  # 2 years for dividend analysis

        price_data = await data_fetcher.fetch_historical_prices(ticker, start_date, end_date)

        if len(price_data) < 30:
            raise HTTPException(status_code=400, detail=f"Insufficient data for {ticker}")

        # Get dividend data (if available from yfinance)
        dividends = None
        try:
            import yfinance as yf
            ticker_obj = yf.Ticker(ticker)
            dividends = ticker_obj.dividends
        except Exception as e:
            logger.warning(f"Could not fetch dividends for {ticker}: {e}")

        # Analyze dividends
        analytics = SpecializedBourseAnalytics()
        result = analytics.analyze_dividends(
            ticker=ticker,
            price_history=price_data,
            dividends=dividends
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[dividends] Error for {ticker}: {e}")
        # Return graceful fallback instead of crashing
        return {
            "ok": False,
            "user_id": user_id,
            "ticker": ticker,
            "error": str(e),
            "current_yield": 0.0,
            "annual_dividend": 0.0,
            "payout_frequency": "unknown",
            "next_ex_dividend_date": None,
            "days_until_ex_dividend": None,
            "avg_price_drop_ex_div": 0.0,
            "total_dividends_12m": 0.0,
            "dividend_growth_rate": 0.0,
            "has_dividend_data": False,
            "note": "Dividend data unavailable or error occurred"
        }


@router.get("/specialized/margin")
async def get_margin_monitoring(
    user_id: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None),
    account_equity: Optional[float] = Query(None, description="Override account equity"),
    maintenance_margin_pct: float = Query(0.25, ge=0.10, le=0.50),
    initial_margin_pct: float = Query(0.50, ge=0.25, le=1.0)
) -> dict:
    """
    Monitor margin requirements for leveraged positions

    Returns margin analysis with warnings and recommendations.

    Example:
        GET /api/risk/bourse/specialized/margin?user_id=jack&account_equity=100000
    """
    try:
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail
        from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics

        logger.info(f"[margin] Monitoring for user {user_id}")

        # Get portfolio positions
        portfolios = list_portfolios_overview(user_id=user_id, file_key=file_key)
        if not portfolios:
            raise HTTPException(status_code=404, detail="No portfolios found")

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user_id, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        # Calculate account equity if not provided
        if account_equity is None:
            account_equity = sum(pos.get('market_value_usd', 0) for pos in positions)

        # Monitor margin
        analytics = SpecializedBourseAnalytics()
        result = analytics.monitor_margin(
            positions=positions,
            account_equity=account_equity,
            maintenance_margin_pct=maintenance_margin_pct,
            initial_margin_pct=initial_margin_pct
        )

        return {
            "ok": True,
            "user_id": user_id,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[margin] Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))


# ============================================================================
# ALERTS SYSTEM
# ============================================================================

@router.get("/alerts")
async def get_risk_alerts(
    user: str = Depends(get_required_user),
    file_key: Optional[str] = Query(None, description="Saxo file key for multi-file support"),
    use_cache: bool = Query(True, description="Use cached alerts if available"),
    redis: Optional[Any] = Depends(get_redis_client)
) -> dict:
    """
    Get risk alerts for bourse portfolio based on moderate risk profile.

    Calibrated for:
    - Horizon: Medium-Long term (6+ months)
    - Risk Profile: Moderate (balanced growth/risk)
    - Management: Active weekly (sector rotation, rebalancing)

    Returns 3 levels of alerts:
    - CRITICAL: Immediate action required (this week)
    - WARNING: Monitor and plan action (2-4 weeks)
    - INFO: Opportunities and context (1-3 months)

    Features:
    - Auto-saves alerts to Redis with 7-day TTL
    - Returns cached alerts if available (use_cache=True)
    - Filters out acknowledged alerts by default
    """
    try:
        logger.info(f"[alerts] Generating alerts for user={user}, file_key={file_key}")

        # Initialize persistence service
        persistence = AlertsPersistenceService(redis_client=redis)

        # Try to get cached alerts first
        if use_cache:
            cached_alerts = persistence.get_current_alerts(user_id=user, include_acknowledged=False)
            if cached_alerts:
                logger.info(f"[alerts] Returning cached alerts for user={user}")
                return {
                    "ok": True,
                    "user_id": user,
                    **cached_alerts
                }

        # Initialize alerts detector
        detector = BourseAlertsDetector()

        # Gather data from existing endpoints (reuse logic)
        from adapters.saxo_adapter import list_portfolios_overview, get_portfolio_detail

        # Get positions
        if file_key:
            portfolios = list_portfolios_overview(user_id=user, file_key=file_key)
        else:
            portfolios = list_portfolios_overview(user_id=user)

        if not portfolios:
            return {
                "ok": False,
                "error": "No portfolios found",
                "critical": [],
                "warnings": [],
                "info": [],
                "summary": {"total": 0, "critical": 0, "warning": 0, "info": 0}
            }

        portfolio_id = portfolios[0].get("portfolio_id")
        portfolio_data = get_portfolio_detail(portfolio_id=portfolio_id, user_id=user, file_key=file_key)
        positions = portfolio_data.get("positions", [])

        if not positions:
            return {
                "ok": False,
                "error": "No positions in portfolio",
                "critical": [],
                "warnings": [],
                "info": [],
                "summary": {"total": 0, "critical": 0, "warning": 0, "info": 0}
            }

        # 1. Get risk dashboard data
        calculator = BourseRiskCalculator()
        risk_data = await calculator.calculate_portfolio_risk(
            positions=positions,
            lookback_days=252,
            risk_free_rate=0.03
        )

        # 2. Try to get ML data (optional, may fail if models not trained)
        ml_data = None
        try:
            from services.ml.bourse.stocks_adapter import StocksMLAdapter
            ml_adapter = StocksMLAdapter()
            regime_data = await ml_adapter.get_regime_detection(benchmark="SPY", lookback_days=365)
            if regime_data:
                ml_data = {"regime": regime_data}
        except Exception as e:
            logger.warning(f"[alerts] ML data not available: {e}")

        # 3. Try to get specialized data (optional)
        specialized_data = {}
        try:
            from services.risk.bourse.specialized_analytics import SpecializedBourseAnalytics
            analytics = SpecializedBourseAnalytics()

            # Get margin data
            account_equity = risk_data.get('total_value_usd', 100000)
            margin_result = analytics.monitor_margin(
                positions=positions,
                account_equity=account_equity
            )
            specialized_data['margin'] = margin_result

            # Get sector rotation data
            sector_result = await analytics.analyze_sector_rotation(positions=positions, lookback_days=60)
            if sector_result and 'sectors' in sector_result:
                specialized_data['sectors'] = sector_result['sectors']
        except Exception as e:
            logger.warning(f"[alerts] Specialized data not available: {e}")

        # Generate alerts
        alerts = detector.detect_alerts(
            risk_data=risk_data,
            ml_data=ml_data,
            specialized_data=specialized_data
        )

        # Save alerts to Redis with TTL
        persistence_result = persistence.save_alerts(
            user_id=user,
            alerts=alerts,
            ttl=7 * 24 * 60 * 60  # 7 days
        )

        if persistence_result.get('persisted'):
            logger.info(f"[alerts] Saved {persistence_result.get('count')} alerts to Redis for user={user}")

        return {
            "ok": True,
            "user_id": user,
            "persisted": persistence_result.get('persisted', False),
            **alerts
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[alerts] Error generating alerts: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/alerts/{alert_id}/acknowledge")
async def acknowledge_alert(
    alert_id: str,
    user: str = Depends(get_required_user),
    redis: Optional[Any] = Depends(get_redis_client)
) -> dict:
    """
    Mark an alert as acknowledged (seen/handled by user).

    Args:
        alert_id: Alert identifier (UUID)
        user_id: User identifier
        redis: Redis client dependency

    Returns:
        Acknowledgment status and timestamp

    Example:
        POST /api/risk/bourse/alerts/abc123/acknowledge?user_id=jack
    """
    try:
        logger.info(f"[alerts] Acknowledging alert {alert_id} for user={user}")

        # Initialize persistence service
        persistence = AlertsPersistenceService(redis_client=redis)

        # Acknowledge the alert
        result = persistence.acknowledge_alert(user_id=user, alert_id=alert_id)

        if not result.get('acknowledged'):
            reason = result.get('reason', 'unknown')
            if reason == 'alert_not_found':
                raise HTTPException(status_code=404, detail=f"Alert {alert_id} not found")
            elif reason == 'redis_unavailable':
                raise HTTPException(status_code=503, detail="Redis unavailable")
            else:
                raise HTTPException(status_code=500, detail=f"Failed to acknowledge alert: {reason}")

        logger.info(f"[alerts] Alert {alert_id} acknowledged at {result.get('acknowledged_at')}")

        return {
            "ok": True,
            "user_id": user,
            **result
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[alerts] Error acknowledging alert: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/alerts/history")
async def get_alerts_history(
    user: str = Depends(get_required_user),
    limit: int = Query(50, ge=1, le=100, description="Maximum number of alerts to return"),
    days_back: int = Query(7, ge=1, le=30, description="Number of days to look back"),
    redis: Optional[Any] = Depends(get_redis_client)
) -> dict:
    """
    Get historical alerts for user (last N days).

    Args:
        user_id: User identifier
        limit: Maximum alerts to return (1-100)
        days_back: Days to look back (1-30)
        redis: Redis client dependency

    Returns:
        List of historical alerts with acknowledgment status

    Example:
        GET /api/risk/bourse/alerts/history?user_id=jack&limit=20&days_back=7
    """
    try:
        logger.info(f"[alerts] Fetching history for user={user}, limit={limit}, days_back={days_back}")

        # Initialize persistence service
        persistence = AlertsPersistenceService(redis_client=redis)

        # Get historical alerts
        alerts = persistence.get_historical_alerts(
            user_id=user,
            limit=limit,
            days_back=days_back
        )

        # Categorize by severity for frontend compatibility
        critical = [a for a in alerts if a.get('severity') == 'critical']
        warnings = [a for a in alerts if a.get('severity') == 'warning']
        info = [a for a in alerts if a.get('severity') == 'info']

        return {
            "ok": True,
            "user_id": user,
            "critical": critical,
            "warnings": warnings,
            "info": info,
            "summary": {
                "total": len(alerts),
                "critical": len(critical),
                "warning": len(warnings),
                "info": len(info)
            },
            "limit": limit,
            "days_back": days_back
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.exception(f"[alerts] Error fetching alerts history: {e}")
        raise HTTPException(status_code=500, detail=str(e))
