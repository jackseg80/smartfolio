# On-Chain Indicators Fix - November 2025

## üêõ Probl√®me Identifi√©

Les indicateurs on-chain ne se mettaient plus √† jour dans le Risk Dashboard.

### Cause Racine
1. **Cache backend** contenait des donn√©es invalides (toutes √† 0.00%)
2. **Cache frontend** (localStorage SWR) servait ces donn√©es stales
3. **Scraping Playwright** √©chouait silencieusement et retournait des donn√©es invalides
4. **Aucune validation** ne d√©tectait ni ne rejetait les donn√©es suspectes

### Sympt√¥mes
```javascript
// Toutes les valeurs √©taient √† 0.00%
{
  "name": "MVRV Z-Score",
  "value_numeric": 0.0,  // ‚ùå Invalid!
  "value": "0.00%"
}
```

---

## ‚úÖ Solutions Impl√©ment√©es

### 1. Backend Validation (`api/crypto_toolbox_endpoints.py`)

#### A. Validation lors du scraping (lignes 335-349)
```python
# Reject if more than 80% of indicators are zero
if zero_percentage > 80:
    logger.error(f"‚ùå Invalid scraping result: {zero_percentage:.1f}% zeros")
    raise Exception("Scraping validation failed - rejecting invalid data")

# Warning if 50-80% are zero
if zero_percentage > 50:
    logger.warning(f"‚ö†Ô∏è Suspicious scraping result: {zero_percentage:.1f}% zeros")
```

**Avantages:**
- D√©tecte les √©checs de scraping Playwright (timeout, page non charg√©e, etc.)
- Rejette imm√©diatement les donn√©es invalides
- Logs d√©taill√©s pour debug

#### B. Protection du cache (lignes 428-445)
```python
# Don't cache invalid data - keep old good cache instead
if zero_percentage > 80 and _cache["data"]:
    logger.error("‚ùå Not caching invalid data - keeping previous cache")
    return {
        **_cache["data"],
        "scraping_failed": True,
        "failure_reason": f"Invalid data detected ({zero_percentage:.1f}% zeros)"
    }
```

**Avantages:**
- Ne permet **jamais** d'√©craser de bonnes donn√©es avec des donn√©es invalides
- Retourne les donn√©es pr√©c√©dentes en fallback
- Signale l'√©chec dans la response (`scraping_failed: true`)

#### C. Fallback intelligent (lignes 469-483)
```python
except Exception as scrape_error:
    # Return old cache if available instead of failing completely
    if _cache["data"]:
        logger.error(f"‚ùå Scraping failed - falling back to stale cache")
        return {
            **_cache["data"],
            "scraping_failed": True,
            "failure_reason": str(scrape_error)
        }
```

**Avantages:**
- Graceful degradation : mieux des donn√©es stales que pas de donn√©es
- L'UI reste fonctionnelle m√™me si le scraping √©choue
- L'utilisateur est inform√© via `scraping_failed` flag

---

### 2. Frontend Validation (`static/modules/onchain-indicators.js`)

#### A. D√©tection backend failure (lignes 895-905)
```javascript
// Detect stale/invalid data from backend
if (apiData.scraping_failed) {
    const reason = apiData.failure_reason || 'Unknown error';
    console.warn(`‚ö†Ô∏è Backend scraping failed: ${reason} - Using stale cache`);
}
```

#### B. Validation frontend double-check (lignes 976-1008)
```javascript
const zeroPercentage = 100 - (nonZeroCount / indicatorValues.length * 100);

if (zeroPercentage > 80) {
    // Show user-visible warning
    window.showToast(
        `‚ö†Ô∏è On-chain data quality issue detected - using fallback`,
        'warning',
        { duration: 10000 }
    );
}
```

**Avantages:**
- D√©tection client-side redondante (d√©fense en profondeur)
- Warning visuel dans l'UI (toast notification)
- M√©tadonn√©es qualit√© dans le cache (`data_quality` object)

---

## üîß Comment Tester

### Test 1 : V√©rifier les donn√©es actuelles
```bash
# Check backend health
curl http://localhost:8080/api/crypto-toolbox/health

# Get current indicators (should have real values now)
curl http://localhost:8080/api/crypto-toolbox | python -m json.tool | head -50
```

**R√©sultat attendu:**
```json
{
    "name": "CBBI*",
    "value_numeric": 69.37,  // ‚úÖ Non-zero!
    "value": "69.37%"
}
```

### Test 2 : Force refresh pour obtenir de nouvelles donn√©es
```bash
# Force backend refresh
curl -X POST http://localhost:8080/api/crypto-toolbox/refresh
```

### Test 3 : Vider le cache frontend
**Option A - Console navigateur:**
```javascript
localStorage.removeItem('CTB_ONCHAIN_CACHE_V2');
location.reload();
```

**Option B - UI:**
1. Ouvrir Risk Dashboard
2. Cliquer sur bouton **‚ãÆ** (options)
3. Cliquer **"Force Refresh"**

---

## üìä Validation Metrics

### Backend (Python)
- **Threshold critique:** 80% zeros ‚Üí Reject & keep old cache
- **Threshold warning:** 50% zeros ‚Üí Log warning but accept
- **Log level:** ERROR pour rejection, WARNING pour suspects, DEBUG pour success

### Frontend (JavaScript)
- **Threshold critique:** 80% zeros ‚Üí Toast warning + error log
- **Threshold warning:** 50% zeros ‚Üí Console warning
- **Cache metadata:** `data_quality.zero_percentage` disponible pour monitoring

---

## üöÄ D√©ploiement

### 1. Red√©marrer le serveur backend
```bash
# IMPORTANT: Les modifications backend n√©cessitent un restart
# Arr√™ter le serveur actuel (Ctrl+C), puis:
.venv\Scripts\Activate.ps1
python -m uvicorn api.main:app --port 8080
```

### 2. Hard refresh frontend
```bash
# Dans le navigateur sur http://localhost:8080/static/risk-dashboard.html
Ctrl + Shift + R  # Hard refresh pour charger nouveau JS
```

### 3. V√©rifier les logs
```bash
# Surveiller les logs pour voir les validations
Get-Content logs\app.log -Wait -Tail 50
```

**Logs attendus (success):**
```
‚úÖ Successfully scraped 30 indicators
‚úÖ Data validation passed: 30/30 indicators have non-zero values
```

**Logs attendus (√©chec d√©tect√©):**
```
‚ùå Invalid scraping result: 93.3% of indicators are zero
‚ùå Not caching invalid data (93.3% zeros) - keeping previous cache
```

---

## üìà Am√©liorations Futures

### Phase 1 : Monitoring (Recommand√©)
- [ ] Endpoint `/api/crypto-toolbox/quality` pour m√©triques qualit√© donn√©es
- [ ] Prometheus metrics : `onchain_indicators_zero_percentage`
- [ ] Alertes si zero_percentage > 50% pendant >1h

### Phase 2 : Retry Logic (Optionnel)
- [ ] Retry automatique si scraping retourne >80% zeros
- [ ] Exponential backoff (1min, 5min, 15min)
- [ ] Circuit breaker apr√®s 3 √©checs cons√©cutifs

### Phase 3 : Fallback Sources (Avanc√©)
- [ ] API secondaire (ex: Glassnode free tier)
- [ ] Donn√©es simul√©es bas√©es sur dernier cycle connu
- [ ] Interpolation intelligente si donn√©es partielles

---

## üîó Fichiers Modifi√©s

### Backend
- `api/crypto_toolbox_endpoints.py` - Validation + cache protection

### Frontend
- `static/modules/onchain-indicators.js` - Double validation + toast warnings

### Documentation
- `docs/ONCHAIN_INDICATORS_FIX_NOV_2025.md` (ce fichier)

---

## ‚úÖ Checklist Post-D√©ploiement

- [ ] Serveur red√©marr√© avec nouveau code
- [ ] Frontend hard-refresh (Ctrl+Shift+R)
- [ ] Cache localStorage vid√© (`CTB_ONCHAIN_CACHE_V2`)
- [ ] Test `/api/crypto-toolbox` retourne valeurs non-zero
- [ ] Test Force Refresh UI fonctionne
- [ ] Logs backend montrent validations
- [ ] Pas de toasts warning en conditions normales
- [ ] Documentation CLAUDE.md mise √† jour si n√©cessaire

---

**Date:** 2025-11-01
**Severity:** High (Impact: Risk Dashboard inutilisable)
**Status:** Fixed ‚úÖ
**Tested:** Backend validation ‚úÖ | Frontend validation ‚úÖ | Cache protection ‚úÖ
