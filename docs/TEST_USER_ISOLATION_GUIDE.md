# Guide d'Isolation Multi-Tenant pour Tests

**CrÃ©Ã©**: Octobre 2025
**Objectif**: Garantir l'isolation des tests pour Ã©viter conflits de donnÃ©es entre users

---

## ğŸ¯ ProblÃ¨me

Les tests utilisaient des `user_id` hardcodÃ©s (`"demo"`, `"jack"`) causant:
- âŒ Conflits entre tests parallÃ¨les
- âŒ Corruption de donnÃ©es de test
- âŒ Faux positifs/nÃ©gatifs alÃ©atoires
- âŒ Violation du principe multi-tenant

## âœ… Solution: Fixtures pytest

### Fixtures Disponibles (`tests/conftest.py`)

#### 1. `test_user_id` - User ID unique par test

```python
@pytest.fixture
def test_user_id(request) -> str:
    """GÃ©nÃ¨re un user_id unique: test_{nom_fonction}_{uuid8}"""
    ...
```

**Usage:**
```python
async def test_balance_resolution(test_user_id):
    # âœ… User ID unique, isolÃ©
    result = await balance_service.resolve_current_balances(
        source="cointracking",
        user_id=test_user_id
    )
    assert result["ok"]
```

#### 2. `test_user_config` - Config complÃ¨te (user_id + source)

```python
@pytest.fixture
def test_user_config(test_user_id) -> Dict[str, str]:
    """Retourne {"user_id": "test_xxx_yyy", "source": "cointracking"}"""
    ...
```

**Usage:**
```python
def test_portfolio_metrics(test_client, test_user_config):
    # âœ… Passe directement le dict comme params
    response = test_client.get(
        "/portfolio/metrics",
        params=test_user_config
    )
    assert response.status_code == 200
```

---

## ğŸ“‹ Migration des Tests Existants

### Pattern 1: Tests unitaires async

**âŒ Avant (hardcodÃ©):**
```python
async def test_snapshot_creation():
    result = await create_snapshot(
        user_id="demo",  # âŒ HardcodÃ©
        source="cointracking"
    )
    assert result["ok"]
```

**âœ… AprÃ¨s (isolÃ©):**
```python
async def test_snapshot_creation(test_user_id):
    result = await create_snapshot(
        user_id=test_user_id,  # âœ… Unique
        source="cointracking"
    )
    assert result["ok"]
```

### Pattern 2: Tests API avec TestClient

**âŒ Avant:**
```python
def test_get_metrics(test_client):
    response = test_client.get(
        "/portfolio/metrics?user_id=jack&source=cointracking"  # âŒ HardcodÃ©
    )
    assert response.status_code == 200
```

**âœ… AprÃ¨s (Option A - params dict):**
```python
def test_get_metrics(test_client, test_user_config):
    response = test_client.get(
        "/portfolio/metrics",
        params=test_user_config  # âœ… user_id + source
    )
    assert response.status_code == 200
```

**âœ… AprÃ¨s (Option B - query string):**
```python
def test_get_metrics(test_client, test_user_id):
    response = test_client.get(
        f"/portfolio/metrics?user_id={test_user_id}&source=cointracking"
    )
    assert response.status_code == 200
```

### Pattern 3: Tests avec setup/teardown

**âœ… Avec cleanup automatique:**
```python
@pytest.fixture
def test_portfolio_data(test_user_id):
    """Setup portfolio data, cleanup aprÃ¨s test"""
    # Setup
    portfolio = create_test_portfolio(user_id=test_user_id)

    yield portfolio

    # Teardown automatique
    cleanup_user_data(user_id=test_user_id)

def test_portfolio_rebalance(test_portfolio_data):
    # Test utilise donnÃ©es isolÃ©es
    result = rebalance(test_portfolio_data)
    assert result["ok"]
    # Cleanup automatique aprÃ¨s le test
```

---

## ğŸ” Fichiers Ã  Migrer (40+ occurrences)

### PrioritÃ© Haute
- [ ] `tests/test_portfolio_pnl.py` (14 occurrences)
- [ ] `tests/integration/test_balance_resolution.py` (8 occurrences)
- [ ] `test_risk_score_v2_divergence.py` (1 occurrence)

### PrioritÃ© Moyenne
- [ ] Tous les tests dans `tests/unit/`
- [ ] Tous les tests dans `tests/integration/`
- [ ] Scripts de test manuels dans `scripts/`

### Commande de dÃ©tection
```bash
# Trouver tous les user_id hardcodÃ©s dans tests
grep -rn 'user_id.*=.*["'"'"']demo["'"'"']' tests/
grep -rn 'user_id.*=.*["'"'"']jack["'"'"']' tests/
```

---

## âš™ï¸ Configuration Scheduler

Les jobs schedulÃ©s ont Ã©galement Ã©tÃ© sÃ©curisÃ©s ([scheduler.py](../api/scheduler.py)):

**Variables d'environnement:**
```bash
# .env
SNAPSHOT_USER_ID=jack      # User pour P&L snapshots
WARMUP_USER_ID=demo        # User pour API warmers
```

**Validation automatique:**
- âœ… Appel `is_allowed_user()` avant exÃ©cution
- âœ… Skip jobs si user_id invalide
- âœ… Log warning + status update
- âœ… Pas de hardcode `user_id=demo` dans code

---

## ğŸ“Š Impact Attendu

### Avant
```
Tests parallÃ¨les: âŒ Ã‰chouent alÃ©atoirement
Isolation: âŒ DonnÃ©es partagÃ©es entre tests
Multi-tenant: âŒ ViolÃ© (hardcode demo/jack)
Debugging: âŒ Difficile (conflits intermittents)
```

### AprÃ¨s
```
Tests parallÃ¨les: âœ… Stables, indÃ©pendants
Isolation: âœ… Chaque test = user unique
Multi-tenant: âœ… RespectÃ©
Debugging: âœ… Facile (logs montrent user_id unique)
```

---

## ğŸš€ Quick Start

1. **Nouveau test unitaire:**
```python
async def test_my_feature(test_user_id):
    result = await my_service.do_something(user_id=test_user_id)
    assert result["ok"]
```

2. **Nouveau test API:**
```python
def test_my_endpoint(test_client, test_user_config):
    response = test_client.get("/my/endpoint", params=test_user_config)
    assert response.status_code == 200
```

3. **Test avec donnÃ©es persistantes:**
```python
@pytest.fixture
def my_test_data(test_user_id):
    data = setup_data(user_id=test_user_id)
    yield data
    cleanup_data(user_id=test_user_id)

def test_with_data(my_test_data):
    assert process(my_test_data)
```

---

## ğŸ“š RÃ©fÃ©rences

- **Fixtures pytest**: [conftest.py](../tests/conftest.py#L244-L304)
- **Validation scheduler**: [scheduler.py](../api/scheduler.py#L27)
- **Config users**: [api/config/users.py](../api/config/users.py)
- **Guide multi-tenant**: [SIMULATOR_USER_ISOLATION_FIX.md](SIMULATOR_USER_ISOLATION_FIX.md)

---

**Note**: Migration progressive recommandÃ©e. PrioritÃ© aux tests qui Ã©chouent en parallÃ¨le.
